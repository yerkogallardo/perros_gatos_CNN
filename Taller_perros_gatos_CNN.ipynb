{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yerkogallardo/perros_gatos_CNN/blob/main/Taller_perros_gatos_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Taller 2 de Redes Neuronales** üß†üí™üèº‚ö°\n",
        "\n",
        "### **Parte pr√°ctica**\n",
        "\n",
        "Esto es un Notebook de desarrollo, es una de las herramientas que los cient√≠ficos de datos usamos de forma cotidiana para trabajar un modelo de Machine Learning o una Red Neuronal.  En este caso, es un notebook en la plataforma Google Colab, que nos permite sin necesidad de instalar nada en nuestro computador trabajar con Python y las librerias con las que vamos a realizar este taller.\n",
        "\n",
        "### **Instrucciones:**\n",
        "\n",
        "En este notebook encontrar√°s todo el c√≥digo para montar una red neuronal capaz de clasificar entre üêï‚Äçü¶∫ y üêà.\n",
        "\n",
        "En cada celda de c√≥digo tendr√°s una parte para que puedas rellenar c√≥digo y algunas donde podr√°s cambiar a tu gusto.\n",
        "\n",
        "Para que el entrenamiento de la red sea mucho m√°s r√°pido te recomiendo activar la aceleraci√≥n por GPU, esto lo podr√°s hacer en la opci√≥n de **Editar** - **Configuraci√≥n de notebook** y ah√≠ cambiar **Aceleracion de hardware** de None a GPU."
      ],
      "metadata": {
        "id": "QjOahjLqkrwA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXfr5UkMDkU-"
      },
      "outputs": [],
      "source": [
        "# Importanci√≥n de las librerias necesarias.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import cv2\n",
        "from skimage import io\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5judpJ_aEL5v"
      },
      "outputs": [],
      "source": [
        "# Agregamos la fuente de datos para descargar el dataset\n",
        "\n",
        "setattr(tfds.image_classification.cats_vs_dogs, \n",
        "        '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-OQVLZ7EtQk"
      },
      "outputs": [],
      "source": [
        "# Descarga del set de datos con perros y gatos con su etiqueta\n",
        "\n",
        "datos, metadatos = tfds.load('cats_vs_dogs', as_supervised=True, with_info=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmMFYiIeFlpK"
      },
      "outputs": [],
      "source": [
        "tfds.show_examples(datos['train'], metadatos)  ## Mostramos ejemplos del set de datos con imagenes de perros y gatos junto con su etiqueta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEIfqL0_MrhX"
      },
      "outputs": [],
      "source": [
        "## Creaci√≥n del diccionario en el cual guardaremos las imagenes procesadas con su etiqueta para el entrenamiento.\n",
        "\n",
        "datos_entrenamiento = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM1UYalcItQm"
      },
      "outputs": [],
      "source": [
        "## En esta parte realizamos el procesamiento de las imagenes las cuales deben ser modificadas \n",
        "## tanto en tama√±o como sus colores para que la red las pueda procesar de mejor manera.\n",
        "\n",
        "for i, (imagen, etiqueta) in enumerate(datos['train']):\n",
        "  imagen = cv2.resize(imagen.numpy(), (100, 100))  # Cambio de tama√±o\n",
        "  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY) # Modifiaci√≥n de color\n",
        "  imagen = imagen.reshape(100, 100, 1) # Guardamos la imagen con su tama√±o y canal de color\n",
        "  datos_entrenamiento.append([imagen, etiqueta])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68RT18XyI9aX",
        "outputId": "0e258fe7-5970-4bbe-b179-8835c906e006"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23262"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(datos_entrenamiento) # Cantidad de datos en total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RHXRjyXNDil"
      },
      "outputs": [],
      "source": [
        "## Preparaci√≥n de variables X (entradas) e y (etiquetas) separadas\n",
        "\n",
        "X = [] #imagenes de entrada (pixeles)\n",
        "y = [] #etiquetas (perro o gato)\n",
        "\n",
        "for imagen, etiqueta in datos_entrenamiento:\n",
        "  X.append(imagen)\n",
        "  y.append(etiqueta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-MKYhDMOZe-"
      },
      "outputs": [],
      "source": [
        "X[0] # Veamos el primer elemento nuestro arreglo en el set de imagenes en pixeles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF-dXLjJOnK8"
      },
      "outputs": [],
      "source": [
        "y[0] # Veamos el primer elemento nuestro arreglo en el set de etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRBgqpvLOPrN"
      },
      "outputs": [],
      "source": [
        "# Normalizac√≥n de los datos\n",
        "X = np.array(X).astype(float) / 255\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYiwi1LHQCkw"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tJTRyPRQ-K7"
      },
      "outputs": [],
      "source": [
        "## Para generar el set de entrenamiento y validaci√≥n debemos considerar del total de datos 80% para entrenamiento y 20% para el test.\n",
        "\n",
        "round(len(X) * 0.80) # Tomamos el 80% de los datos que ser√≠an aproximadamente 18610 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsWHFmw6RVzu"
      },
      "outputs": [],
      "source": [
        "len(X) - round(len(X) * 0.80) # El 20% restante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZCTUvfDSHkN"
      },
      "outputs": [],
      "source": [
        "## Creaci√≥n de los set de datos de entrenamiento y validaci√≥n\n",
        "\n",
        "X_entrenamiento = X[:]  # Reemplaza dentro del parentesis de corchete y despu√©s de los dos puntos el valor de 18610\n",
        "X_validacion = X[:] # Reemplaza dentro del parentesis de corchete y antes de los dos puntos el valor de 18610\n",
        "\n",
        "y_entrenamiento = y[:]  # Reemplaza dentro del parentesis de corchete y despu√©s de los dos puntos el valor de 18610\n",
        "y_validacion = y[:]  # Reemplaza dentro del parentesis de corchete y antes de los dos puntos el valor de 18610"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKWYLLBsTYRL"
      },
      "outputs": [],
      "source": [
        "# Generaci√≥n de transforamciones de imagenes para el aprendizaje convolucional de la red\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center = False,  # establecer la media de entrada en 0 sobre el conjunto de datos\n",
        "        samplewise_center = False,  # establecer la media de cada muestra en 0\n",
        "        featurewise_std_normalization = False,  # dividir inputs por std del dataset\n",
        "        samplewise_std_normalization = False,  # dividir cada input por std\n",
        "        zca_whitening = False,  # apply ZCA whitening\n",
        "        rotation_range = 30,  # rotaci√≥n aleatoria de imagenes seg√∫n rangos de 0 a 180 grados\n",
        "        zoom_range = 0.2, # zoom o acercamiento aleatorio de imagen \n",
        "        width_shift_range=0.1,  # cambio aleatorio de las im√°genes horizontalmente\n",
        "        height_shift_range=0.1,  # cambio aleatorio de las im√°genes verticalmente\n",
        "        horizontal_flip = True,  # giro aleatorio de imagen\n",
        "        vertical_flip = False)  # giro aleatorio de imagen\n",
        "\n",
        "\n",
        "datagen.fit(X_entrenamiento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caswA0T2UOxc"
      },
      "outputs": [],
      "source": [
        "## Definici√≥n de capas en red neuronal\n",
        "\n",
        "## Capa de entrada\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(100,100,1)))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "## Capas convolucionales ocultas\n",
        "## Capa convolucional de 32 filtros y kernel de 3\n",
        "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "## Agrega una capa convolucional de 64 filtros y un kernel de tama√±o 3  \n",
        "\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "## Capa de salida\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation=\"relu\"))\n",
        "model.add(Dense(2, activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhsEzxdmU7EC"
      },
      "outputs": [],
      "source": [
        "opt = Adam(learning_rate=0.000001)\n",
        "\n",
        "model.compile(optimizer = opt, \n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0WBJX0FVDbb"
      },
      "outputs": [],
      "source": [
        "## Realizamos el entrenamiento de la red neuronal, puedes cambiar las √©pocas en la variable epoca\n",
        "## Pero te recordamos que mientras mas √©pocas entrenes m√°s se va a demorar la red neuronal en generar el modelo\n",
        "\n",
        "epocas =  ## escribe la cantidad de √©pocas que quieres entrenar\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "history = model.fit(X_entrenamiento,\n",
        "                    y_entrenamiento,\n",
        "                    epochs = epocas,\n",
        "                    validation_data = (X_validacion, y_validacion), callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "na9tdZd2W4MF"
      },
      "outputs": [],
      "source": [
        "## Revisamos utilizando gr√°ficos el desempe√±o del modelo y su p√©rdida.\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epocas)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpoBWkYn_HhM"
      },
      "outputs": [],
      "source": [
        "## Veamos como nos va con la red neuronal, para eso desplegamos las m√©tricas del modelo.\n",
        "\n",
        "predict_x=model.predict(X_validacion)\n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "print(classification_report(y_validacion, classes_x, target_names = ['cats (Class 0)','dog (Class 1)']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funci√≥n para predicci√≥n"
      ],
      "metadata": {
        "id": "ZHuzyhpmxRP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow ## Agregamos esta librer√≠a para procesar imagenes de predicci√≥n."
      ],
      "metadata": {
        "id": "gu1skQYMBrWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creamos una funci√≥n para realizar predicciones\n",
        "\n",
        "def clasificador(imagen):\n",
        "  # Obtiene la imagen y la transforma para mostrarla junto con su resultado.\n",
        "  img_source = cv2.imread(imagen)\n",
        "  img_source = cv2.resize(img_source,(224, 224))\n",
        "  cv2_imshow(img_source)\n",
        "\n",
        "  # Procesamiento de imagen para evaluar en el modelo.\n",
        "  imagen = cv2.imread(imagen)\n",
        "  imagen = cv2.resize(imagen, (100, 100))\n",
        "  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
        "  imagen = imagen.reshape(1, 100, 100, 1)\n",
        "\n",
        "  # Realizaci√≥n de la predicci√≥n.\n",
        "  pred_mod = modelo.predict(imagen) \n",
        "\n",
        "  # En esta parte realizamos el tratamiento del resultado del modelo.\n",
        "  classes_x=np.argmax(pred_mod,axis=1)\n",
        "  pred_val = (modelo.predict(imagen) > 0.5).astype(\"int32\")\n",
        "  \n",
        "  if classes_x == 0:\n",
        "    pred_class ='Gato üò∫'\n",
        "  else:\n",
        "    pred_class ='Perro üê∂'\n",
        "\n",
        "  # Entrega de resultados.\n",
        "  print(pred_mod)\n",
        "  print(pred_val)\n",
        "  print(pred_class)"
      ],
      "metadata": {
        "id": "2bYe3zC5H45s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ahora vamos a hacer pruebas"
      ],
      "metadata": {
        "id": "YWwiQ2Nkd-yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Importamos librerias para hacer las pruebas\n",
        "\n",
        "from google.colab import files\n",
        "from IPython. display import Image"
      ],
      "metadata": {
        "id": "_0cSC-omCZMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "nombre_archivo = next(iter(uploaded))\n",
        "clasificador(nombre_archivo)"
      ],
      "metadata": {
        "id": "5jc6gXNNC8m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "nombre_archivo = next(iter(uploaded))\n",
        "clasificador(nombre_archivo)"
      ],
      "metadata": {
        "id": "qv3mdOHZoyvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "nombre_archivo = next(iter(uploaded))\n",
        "clasificador(nombre_archivo)"
      ],
      "metadata": {
        "id": "aVoP9K5Zw2vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "nombre_archivo = next(iter(uploaded))\n",
        "clasificador(nombre_archivo)"
      ],
      "metadata": {
        "id": "SN5UQEO4w2f0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Taller_perros_gatos_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MsJ2b86Jp7ak_t8UD7HrKbVCOaRK6TQ0",
      "authorship_tag": "ABX9TyOEI1X10N/my93/Fb3gWhYa",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}